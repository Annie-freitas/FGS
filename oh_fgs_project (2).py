# -- coding: utf-8 --
"""OH-FGS  Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c7vmzYncGBP226UiQpgEo9lBgZeJD1wQ

IMPORT LIBRARIES
"""

# 2. Import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# 3. Load dataset (upload your Excel file when prompted)
import streamlit as st
import pandas as pd

uploaded_file = st.file_uploader("Upload OH-FGS Excel file", type=["xlsx"])
if uploaded_file:
    df = pd.read_excel(uploaded_file)
    st.write(df.head())
else:
    st.warning("Please upload an Excel file")

# 4. Feature Selection (One Health Approach)
# Key variables from your dataset + engineered features
one_health_features = [
    # Human Health
    'n_ShInfection',       # Primary target (binary: outbreak if >50)
    'mean_ShEgg',          # Egg burden (continuous)
    'n_female',            # FGS risk group
    'Pop',                 # Population density

    # Environmental
    'LakeYN',              # Lake presence (binary)
    'distance',            # Proximity to water (meters)
    'FloatingVeg',         # Snail habitat indicator
    'Depth',               # Water depth (snail survival)
    'width_shore',         # Shoreline width (transmission zone)

    # Animal/Vector
    'Bulinus',             # Snail vector count
    'Biomph',              # Alternative snail vector
    'circ_score'           # Water body circularity (snail habitat)
]

# Create new features
df['water_contact_risk'] = np.where(df['distance'] < 1000, 1, 0)  # High risk if <1km to water
df['snail_density'] = df['Bulinus'] + df['Biomph']               # Total snail load

# 5. Prepare data
X = df[one_health_features]
y = np.where(df['n_ShInfection'] > 50, 1, 0)  # Binary outbreak target (1 if >50 cases)

# 6. Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# 7. Train model (Random Forest)
rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
rf_model.fit(X_train, y_train)

dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)

xg_model = XGBClassifier(random_state=42)
xg_model.fit(X_train, y_train)

lg_model = LogisticRegression(random_state=42)
lg_model.fit(X_train, y_train)

# 8. Evaluate

#Evaluate Random Forest model
y_pred_rf = rf_model.predict(X_test)
print("Random Forest Model Evaluation:")
print(classification_report(y_test, y_pred_rf))
print(f"AUC-ROC: {roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]):.2f}")

# Evaluate Decision Tree model
y_pred_dt = dt_model.predict(X_test)
print("Decision Tree Model Evaluation:")
print(classification_report(y_test, y_pred_dt))
print(f"AUC-ROC: {roc_auc_score(y_test, dt_model.predict_proba(X_test)[:, 1]):.2f}")

# Evaluate XGBoost model
y_pred_xg = xg_model.predict(X_test)
print("\nXGBoost Model Evaluation:")
print(classification_report(y_test, y_pred_xg))
print(f"AUC-ROC: {roc_auc_score(y_test, xg_model.predict_proba(X_test)[:, 1]):.2f}")

# Evaluate Logistic Regression model
y_pred_lg = lg_model.predict(X_test)
print("\nLogistic Regression Model Evaluation:")
print(classification_report(y_test, y_pred_lg))
print(f"AUC-ROC: {roc_auc_score(y_test, lg_model.predict_proba(X_test)[:, 1]):.2f}")

# 9. Feature Importance
plt.figure(figsize=(10, 6))
sns.barplot(x=rf_model.feature_importances_, y=one_health_features)
plt.title("One Health Feature Importance")
plt.show()

import seaborn as sns
df['risk_score'] = lg_model.predict_proba(X)[:, 1]

# Now, the heatmap code should work
# Pivot table: Village x Site risk scores
heatmap_data = df.pivot_table(index='Village', columns='Site',
                             values='risk_score', aggfunc='mean')

# Plot
plt.figure(figsize=(12, 8))
sns.heatmap(heatmap_data, annot=True, cmap="YlOrRd",
            linewidths=0.5, cbar_kws={'label': 'Risk Score'})
plt.title("Schisto Risk by Village and Site")
plt.show()

import pickle

# Save the model
chosen_model = lg_model
with open('schisto_risk_model.pkl', 'wb') as f:
    pickle.dump(chosen_model, f)

print("LGR model saved as schisto_risk_model.pkl")

def send_stakeholder_alerts(village_data, risk_level):
    # Single recipient (modify this to your target email)
    recipient_email = "freitasannie7@gmail.com"

    # Compose the alert message
    message = f"""
    üö® SCHISTOSOMIASIS ALERT - {village_data['Village']} üö®
    Risk Level: {risk_level}
    Risk Score: {village_data['risk_score']:.2f}

    üìç Location: Site {village_data['Site']}
    üìä Metrics:
    - Infected Individuals: {village_data['n_ShInfection']}
    - Bulinus Snail Count: {village_data['Bulinus']}
    - Water Contact Risk: {village_data['distance']}m from village

    ‚ö† Recommended Actions:
    {generate_intervention_plan(village_data)}

    üìÖ Next Assessment: {pd.Timestamp.now() + pd.Timedelta(days=7)}
    """

    # Send only one email
    send_email(recipient_email, f"SCHISTO ALERT: {risk_level} Risk Detected", message)

    # Optional: Log the alert (no SMS or emergency protocols)
    print(f"üìß Alert sent to {recipient_email} for {village_data['Village']}")

import pandas as pd
import numpy as np

# Track Intervention Effectiveness
def evaluate_impact(baseline, follow_up):
    improvement = {
        'Risk Reduction': baseline['risk_score'] - follow_up['risk_score'],
        'Case Reduction': (baseline['n_ShInfection'] - follow_up['n_ShInfection'])/baseline['n_ShInfection']*100,
        'Snail Reduction': (baseline['Bulinus'] - follow_up['Bulinus'])/baseline['Bulinus']*100
    }
    return improvement

# Example Report
# Replace 'Diokhor' with an actual Village name from your dataset (e.g., 'Diokhor ')
baseline = df[df['Village']=='Diokhor '].iloc[0]
follow_up = baseline.copy()  # Replace with actual follow-up data
follow_up.update({'risk_score': baseline['risk_score']*0.6,
                 'n_ShInfection': baseline['n_ShInfection']*0.7,
                 'Bulinus': baseline['Bulinus']*0.5})

print("üìà Intervention Effectiveness:")
st.dataframe(pd.DataFrame([evaluate_impact(baseline, follow_up)]))

# -- coding: utf-8 --
import streamlit as st
import pandas as pd
import numpy as np
import pickle
import matplotlib.pyplot as plt
from datetime import datetime
from sklearn.metrics import classification_report

# Set page config
st.set_page_config(
    page_title="OH-FGS Risk Prediction",
    page_icon="ü¶†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
st.markdown("""
<style>
    .risk-high { color: red; font-weight: bold; }
    .risk-medium { color: orange; }
    .risk-low { color: green; }
    .debug-info { font-family: monospace; background: #f5f5f5; padding: 10px; }
</style>
""", unsafe_allow_html=True)

# Load model with validation
@st.cache_resource
def load_model():
    try:
        with open('schisto_risk_model.pkl', 'rb') as f:
            model = pickle.load(f)
            
            # Validate model structure
            if not hasattr(model, 'predict_proba'):
                st.error("Invalid model: Missing predict_proba method")
                return None
                
            return model
    except Exception as e:
        st.error(f"Model loading failed: {str(e)}")
        return None

model = load_model()

# Feature information
FEATURES = {
    'n_ShInfection': {'type': 'int', 'min': 0, 'default': 10, 'desc': 'Number of infected individuals'},
    'mean_ShEgg': {'type': 'float', 'min': 0, 'default': 5.2, 'desc': 'Average egg count per infection'},
    'n_female': {'type': 'int', 'min': 0, 'default': 15, 'desc': 'Number of females in population'},
    'Pop': {'type': 'int', 'min': 0, 'default': 200, 'desc': 'Total population'},
    'LakeYN': {'type': 'binary', 'options': ['No', 'Yes'], 'default': 'Yes', 'desc': 'Presence of lake'},
    'distance': {'type': 'int', 'min': 0, 'default': 500, 'desc': 'Distance to water (meters)'},
    'FloatingVeg': {'type': 'category', 'options': ['Low', 'Medium', 'High'], 'default': 'Medium', 'desc': 'Vegetation density'},
    'Depth': {'type': 'float', 'min': 0, 'default': 1.5, 'desc': 'Water depth (meters)'},
    'width_shore': {'type': 'float', 'min': 0, 'default': 10.0, 'desc': 'Shoreline width (meters)'},
    'Bulinus': {'type': 'int', 'min': 0, 'default': 20, 'desc': 'Bulinus snail count'},
    'Biomph': {'type': 'int', 'min': 0, 'default': 5, 'desc': 'Biomphalaria snail count'},
    'circ_score': {'type': 'float', 'min': 0, 'max': 1, 'default': 0.7, 'desc': 'Water circularity score'}
}

# Risk thresholds (adjustable)
DEFAULT_THRESHOLDS = {
    'low': 0.3,
    'medium': 0.7,
    'high': 1.0
}

# Initialize session state
if 'saved_data' not in st.session_state:
    st.session_state.saved_data = pd.DataFrame(columns=list(FEATURES.keys()) + ['Village', 'Site', 'Date', 'Risk_Level', 'Risk_Probability'])
if 'thresholds' not in st.session_state:
    st.session_state.thresholds = DEFAULT_THRESHOLDS

# Model validation function
def validate_model(input_data):
    results = {}
    
    # Check feature importance
    if hasattr(model, 'feature_importances_'):
        fig, ax = plt.subplots()
        pd.Series(model.feature_importances_, index=input_data.columns).plot.bar(ax=ax)
        ax.set_title("Feature Importance")
        results['feature_importance'] = fig
    
    # Generate sample predictions
    sample_data = {
        'low_risk': input_data.mean() * 0.5,
        'medium_risk': input_data.mean(),
        'high_risk': input_data.mean() * 2
    }
    
    sample_preds = {}
    for name, values in sample_data.items():
        sample_preds[name] = model.predict_proba(pd.DataFrame([values]))[0][1]
    
    results['sample_predictions'] = sample_preds
    
    return results

# Prediction function with debugging
def predict_risk(features, debug=False):
    try:
        # Convert to DataFrame if single sample
        if isinstance(features, dict):
            features = pd.DataFrame([features])
        
        # Ensure correct feature order
        features = features[list(FEATURES.keys())]
        
        # Get probabilities
        proba = model.predict_proba(features)[:, 1]
        
        # Apply thresholds
        risk_levels = []
        for p in proba:
            if p <= st.session_state.thresholds['low']:
                risk_levels.append("Low")
            elif p <= st.session_state.thresholds['medium']:
                risk_levels.append("Medium")
            else:
                risk_levels.append("High")
        
        if debug:
            debug_info = {
                'input_features': features.iloc[0].to_dict(),
                'probability': proba[0],
                'risk_level': risk_levels[0],
                'thresholds': st.session_state.thresholds
            }
            return risk_levels[0], proba[0], debug_info
        
        return risk_levels, proba
    
    except Exception as e:
        st.error(f"Prediction failed: {str(e)}")
        return None

# Individual entry form
def individual_entry_form():
    with st.expander("üß™ Test Example Data", expanded=False):
        col1, col2, col3 = st.columns(3)
        with col1:
            if st.button("Low Risk Example"):
                st.session_state.example = 'low'
        with col2:
            if st.button("Medium Risk Example"):
                st.session_state.example = 'medium'
        with col3:
            if st.button("High Risk Example"):
                st.session_state.example = 'high'

    with st.form("individual_entry"):
        st.subheader("Individual Data Entry")
        
        # Dynamic form based on FEATURES dict
        inputs = {}
        cols = st.columns(3)
        col_idx = 0
        
        for feature, config in FEATURES.items():
            with cols[col_idx % 3]:
                if config['type'] == 'int':
                    inputs[feature] = st.number_input(
                        f"{feature} ({config['desc']})",
                        min_value=config['min'],
                        value=config['default']
                    )
                elif config['type'] == 'float':
                    inputs[feature] = st.number_input(
                        f"{feature} ({config['desc']})",
                        min_value=config.get('min', 0.0),
                        max_value=config.get('max', None),
                        value=config['default'],
                        step=0.1
                    )
                elif config['type'] == 'binary':
                    inputs[feature] = 1 if st.selectbox(
                        f"{feature} ({config['desc']})",
                        options=config['options'],
                        index=config['options'].index(config['default'])
                    ) == "Yes" else 0
                elif config['type'] == 'category':
                    inputs[feature] = st.selectbox(
                        f"{feature} ({config['desc']})",
                        options=config['options'],
                        index=config['options'].index(config['default'])
                    )
                    # Convert to numerical (simple encoding)
                    inputs[feature] = config['options'].index(inputs[feature]) + 1
                
                col_idx += 1
        
        # Metadata
        inputs['Village'] = st.text_input("Village Name", "Diokhor")
        inputs['Site'] = st.text_input("Site Number", "1")
        inputs['Date'] = st.date_input("Date", datetime.today())
        
        submitted = st.form_submit_button("Submit & Predict")
        
        if submitted:
            # Convert FloatingVeg to numerical
            if 'FloatingVeg' in inputs and isinstance(inputs['FloatingVeg'], str):
                inputs['FloatingVeg'] = ['Low', 'Medium', 'High'].index(inputs['FloatingVeg']) + 1
            
            # Make prediction with debugging
            risk_level, proba, debug_info = predict_risk(inputs, debug=True)
            
            # Display results
            st.subheader("Prediction Results")
            risk_class = f"risk-{risk_level.lower()}"
            st.markdown(f"### Risk Level: <span class='{risk_class}'>{risk_level}</span>", unsafe_allow_html=True)
            st.markdown(f"Probability: **{proba:.2%}**")
            
            # Add to session data
            inputs.update({
                'Risk_Level': risk_level,
                'Risk_Probability': proba
            })
            st.session_state.saved_data = pd.concat([
                st.session_state.saved_data,
                pd.DataFrame([inputs])
            ], ignore_index=True)
            
            # Debug info
            with st.expander("üîç Debug Information"):
                st.json(debug_info)

# Model validation tab
def validation_tab():
    st.subheader("Model Validation")
    
    # Threshold adjustment
    st.markdown("### Risk Thresholds")
    col1, col2, col3 = st.columns(3)
    with col1:
        st.session_state.thresholds['low'] = st.slider(
            "Low Risk Threshold", 
            0.0, 1.0, st.session_state.thresholds['low'], 0.05
        )
    with col2:
        st.session_state.thresholds['medium'] = st.slider(
            "Medium Risk Threshold", 
            st.session_state.thresholds['low'], 1.0, st.session_state.thresholds['medium'], 0.05
        )
    with col3:
        st.session_state.thresholds['high'] = 1.0  # Fixed upper bound
    
    # Generate test cases
    st.markdown("### Test Cases")
    test_cases = pd.DataFrame({
        'n_ShInfection': [10, 30, 60],
        'mean_ShEgg': [5, 15, 30],
        'Bulinus': [5, 20, 50],
        'distance': [1000, 500, 100]
    })
    
    # Add predictions
    test_cases['Risk_Probability'] = model.predict_proba(test_cases)[:, 1]
    test_cases['Risk_Level'] = predict_risk(test_cases)[0]
    
    st.dataframe(test_cases.style.applymap(
        lambda x: 'background-color: #ffcccc' if x == 'High' else 
                 ('background-color: #fff3cd' if x == 'Medium' else 'background-color: #d4edda'),
        subset=['Risk_Level']
    ))

# Main app
def main():
    st.title("üî¨ OH-FGS Risk Prediction with Validation")
    
    tab1, tab2, tab3 = st.tabs(["Data Entry", "Model Validation", "Collected Data"])
    
    with tab1:
        individual_entry_form()
    
    with tab2:
        if model is not None:
            validation_tab()
        else:
            st.error("Model not loaded - cannot validate")
    
    with tab3:
        st.subheader("Collected Data")
        if not st.session_state.saved_data.empty:
            st.dataframe(st.session_state.saved_data)
            
            # Export options
            st.download_button(
                label="Download Data",
                data=st.session_state.saved_data.to_csv(index=False),
                file_name="schisto_data.csv",
                mime="text/csv"
            )
        else:
            st.info("No data collected yet")

if __name__ == "__main__":
    main()
