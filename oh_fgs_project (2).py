# -- coding: utf-8 --
"""OH-FGS  Project

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1c7vmzYncGBP226UiQpgEo9lBgZeJD1wQ

IMPORT LIBRARIES
"""
# 2. Import libraries
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.metrics import classification_report, roc_auc_score
import matplotlib.pyplot as plt
import seaborn as sns
import joblib

# 3. Load dataset (upload your Excel file when prompted)
import streamlit as st
import pandas as pd

uploaded_file = st.file_uploader("Upload OH-FGS Excel file", type=["xlsx"])
if uploaded_file:
    df = pd.read_excel(uploaded_file)
    st.write(df.head())
else:
    st.warning("Please upload an Excel file")

# 4. Feature Selection (One Health Approach)
# Key variables from your dataset + engineered features
one_health_features = [
    # Human Health
    'n_ShInfection',       # Primary target (binary: outbreak if >50)
    'mean_ShEgg',          # Egg burden (continuous)
    'n_female',            # FGS risk group
    'Pop',                 # Population density

    # Environmental
    'LakeYN',              # Lake presence (binary)
    'distance',            # Proximity to water (meters)
    'FloatingVeg',         # Snail habitat indicator
    'Depth',               # Water depth (snail survival)
    'width_shore',         # Shoreline width (transmission zone)

    # Animal/Vector
    'Bulinus',             # Snail vector count
    'Biomph',              # Alternative snail vector
    'circ_score'           # Water body circularity (snail habitat)
]

# Create new features
df['water_contact_risk'] = np.where(df['distance'] < 1000, 1, 0)  # High risk if <1km to water
df['snail_density'] = df['Bulinus'] + df['Biomph']               # Total snail load

# 5. Prepare data
X = df[one_health_features]
y = np.where(df['n_ShInfection'] > 50, 1, 0)  # Binary outbreak target (1 if >50 cases)

# 6. Train/test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)

# 7. Train model (Random Forest)
rf_model = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)
rf_model.fit(X_train, y_train)

dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)

xg_model = XGBClassifier(random_state=42)
xg_model.fit(X_train, y_train)

lg_model = LogisticRegression(random_state=42)
lg_model.fit(X_train, y_train)

# 8. Evaluate

#Evaluate Random Forest model
y_pred_rf = rf_model.predict(X_test)
print("Random Forest Model Evaluation:")
print(classification_report(y_test, y_pred_rf))
print(f"AUC-ROC: {roc_auc_score(y_test, rf_model.predict_proba(X_test)[:, 1]):.2f}")

# Evaluate Decision Tree model
y_pred_dt = dt_model.predict(X_test)
print("Decision Tree Model Evaluation:")
print(classification_report(y_test, y_pred_dt))
print(f"AUC-ROC: {roc_auc_score(y_test, dt_model.predict_proba(X_test)[:, 1]):.2f}")

# Evaluate XGBoost model
y_pred_xg = xg_model.predict(X_test)
print("\nXGBoost Model Evaluation:")
print(classification_report(y_test, y_pred_xg))
print(f"AUC-ROC: {roc_auc_score(y_test, xg_model.predict_proba(X_test)[:, 1]):.2f}")

# Evaluate Logistic Regression model
y_pred_lg = lg_model.predict(X_test)
print("\nLogistic Regression Model Evaluation:")
print(classification_report(y_test, y_pred_lg))
print(f"AUC-ROC: {roc_auc_score(y_test, lg_model.predict_proba(X_test)[:, 1]):.2f}")

# 9. Feature Importance
plt.figure(figsize=(10, 6))
sns.barplot(x=rf_model.feature_importances_, y=one_health_features)
plt.title("One Health Feature Importance")
plt.show()

import seaborn as sns
df['risk_score'] = lg_model.predict_proba(X)[:, 1]

# Now, the heatmap code should work
# Pivot table: Village x Site risk scores
heatmap_data = df.pivot_table(index='Village', columns='Site',
                             values='risk_score', aggfunc='mean')

# Plot
plt.figure(figsize=(12, 8))
sns.heatmap(heatmap_data, annot=True, cmap="YlOrRd",
            linewidths=0.5, cbar_kws={'label': 'Risk Score'})
plt.title("Schisto Risk by Village and Site")
plt.show()

import pickle

# Save the model
chosen_model = lg_model
with open('schisto_risk_model.pkl', 'wb') as f:
    pickle.dump(chosen_model, f)

print("LGR model saved as schisto_risk_model.pkl")

def send_stakeholder_alerts(village_data, risk_level):
    # Single recipient (modify this to your target email)
    recipient_email = "freitasannie7@gmail.com"

    # Compose the alert message
    message = f"""
    üö® SCHISTOSOMIASIS ALERT - {village_data['Village']} üö®
    Risk Level: {risk_level}
    Risk Score: {village_data['risk_score']:.2f}

    üìç Location: Site {village_data['Site']}
    üìä Metrics:
    - Infected Individuals: {village_data['n_ShInfection']}
    - Bulinus Snail Count: {village_data['Bulinus']}
    - Water Contact Risk: {village_data['distance']}m from village

    ‚ö† Recommended Actions:
    {generate_intervention_plan(village_data)}

    üìÖ Next Assessment: {pd.Timestamp.now() + pd.Timedelta(days=7)}
    """

    # Send only one email
    send_email(recipient_email, f"SCHISTO ALERT: {risk_level} Risk Detected", message)

    # Optional: Log the alert (no SMS or emergency protocols)
    print(f"üìß Alert sent to {recipient_email} for {village_data['Village']}")

import pandas as pd
import numpy as np

# Track Intervention Effectiveness
def evaluate_impact(baseline, follow_up):
    improvement = {
        'Risk Reduction': baseline['risk_score'] - follow_up['risk_score'],
        'Case Reduction': (baseline['n_ShInfection'] - follow_up['n_ShInfection'])/baseline['n_ShInfection']*100,
        'Snail Reduction': (baseline['Bulinus'] - follow_up['Bulinus'])/baseline['Bulinus']*100
    }
    return improvement

# Example Report
# Replace 'Diokhor' with an actual Village name from your dataset (e.g., 'Diokhor ')
baseline = df[df['Village']=='Diokhor '].iloc[0]
follow_up = baseline.copy()  # Replace with actual follow-up data
follow_up.update({'risk_score': baseline['risk_score']*0.6,
                 'n_ShInfection': baseline['n_ShInfection']*0.7,
                 'Bulinus': baseline['Bulinus']*0.5})

print("üìà Intervention Effectiveness:")
st.dataframe(pd.DataFrame([evaluate_impact(baseline, follow_up)]))

# -- coding: utf-8 --
import streamlit as st
import pandas as pd
import numpy as np
import pickle
from datetime import datetime
from io import BytesIO

# Set page config
st.set_page_config(
    page_title="OH-FGS Risk Prediction",
    page_icon="ü¶†",
    layout="wide"
)

# Custom CSS
st.markdown("""
<style>
    .risk-high { background-color: #ffdddd; padding: 15px; border-radius: 10px; }
    .risk-medium { background-color: #fff3cd; padding: 15px; border-radius: 10px; }
    .risk-low { background-color: #d4edda; padding: 15px; border-radius: 10px; }
    .intervention-card { padding: 10px; border-radius: 5px; margin: 5px 0; }
</style>
""", unsafe_allow_html=True)

# Initialize session state
if 'submitted_data' not in st.session_state:
    st.session_state.submitted_data = pd.DataFrame()

def _load_model():
    try:
        with open('schisto_risk_model.pkl', 'rb') as f:
            return pickle.load(f)
    except Exception as e:
        st.error(f"Model loading failed: {str(e)}")
        return None

def predict_risk(input_data):
    model = _load_model()
    if model is None:
        return None, None
    
    try:
        # Create features exactly as they were during training
        features = [
            'n_ShInfection', 'mean_ShEgg', 'n_female', 'Pop', 'LakeYN',
            'distance', 'FloatingVeg', 'Depth', 'width_shore', 'Bulinus',
            'Biomph', 'circ_score'
        ]
        
        # Prepare input data with only the expected features
        X = pd.DataFrame([[
            input_data['n_ShInfection'],
            input_data['mean_ShEgg'],
            input_data['n_female'],
            input_data['Pop'],
            input_data['LakeYN'],
            input_data['distance'],
            input_data['FloatingVeg'],
            input_data['Depth'],
            input_data['width_shore'],
            input_data['Bulinus'],
            input_data['Biomph'],
            input_data['circ_score']
        ], columns=features)
        
        # Make prediction
        proba = model.predict_proba(X)[0][1]
        risk_level = "High" if proba > 0.7 else "Medium" if proba > 0.3 else "Low"
        
        return risk_level, proba
    except Exception as e:
        st.error(f"Prediction error: {str(e)}")
        return None, None

def get_interventions(risk_level):
    interventions = {
        "High": [
            "Immediate mass drug administration (MDA)",
            "Intensive snail control measures",
            "Community-wide health education",
            "Water source improvement",
            "Weekly monitoring"
        ],
        "Medium": [
            "Targeted treatment of high-risk groups",
            "Focal snail control",
            "Health education sessions",
            "Improved sanitation",
            "Monthly monitoring"
        ],
        "Low": [
            "Health education in schools",
            "Passive surveillance",
            "Environmental modification",
            "Quarterly monitoring"
        ]
    }
    return interventions.get(risk_level, [])

def show_input_form():
    with st.form("risk_form"):
        st.header("Individual Case Assessment")
        
        col1, col2 = st.columns(2)
        
        with col1:
            village = st.text_input("Village Name", "Diokhor")
            site = st.text_input("Site Number", "1")
            date = st.date_input("Assessment Date", datetime.today())
            n_ShInfection = st.number_input("Number of Infections", min_value=0, value=5)
            mean_ShEgg = st.number_input("Mean Egg Count", min_value=0.0, value=2.5, step=0.1)
            
        with col2:
            n_female = st.number_input("Female Population", min_value=0, value=15)
            pop = st.number_input("Total Population", min_value=0, value=100)
            lake_yn = st.selectbox("Lake Present", ["Yes", "No"])
            distance = st.number_input("Distance to Water (m)", min_value=0, value=500)
            floating_veg = st.selectbox("Floating Vegetation", ["Low", "Medium", "High"])
        
        col3, col4 = st.columns(2)
        with col3:
            depth = st.number_input("Water Depth (m)", min_value=0.0, value=1.2, step=0.1)
            width_shore = st.number_input("Shore Width (m)", min_value=0.0, value=8.0, step=0.1)
        with col4:
            bulinus = st.number_input("Bulinus Snail Count", min_value=0, value=15)
            biomph = st.number_input("Biomph Snail Count", min_value=0, value=3)
            circ_score = st.slider("Water Circularity Score", 0.0, 1.0, 0.6, step=0.01)
        
        if st.form_submit_button("Assess Risk"):
            input_data = {
                'Village': village,
                'Site': site,
                'Date': date.strftime('%Y-%m-%d'),
                'n_ShInfection': n_ShInfection,
                'mean_ShEgg': mean_ShEgg,
                'n_female': n_female,
                'Pop': pop,
                'LakeYN': 1 if lake_yn == "Yes" else 0,
                'distance': distance,
                'FloatingVeg': ["Low", "Medium", "High"].index(floating_veg) + 1,
                'Depth': depth,
                'width_shore': width_shore,
                'Bulinus': bulinus,
                'Biomph': biomph,
                'circ_score': circ_score
            }
            
            risk_level, risk_proba = predict_risk(input_data)
            
            if risk_level:
                input_data.update({
                    'Risk_Level': risk_level,
                    'Risk_Probability': risk_proba
                })
                
                # Add to session data
                new_entry = pd.DataFrame([input_data])
                st.session_state.submitted_data = pd.concat(
                    [st.session_state.submitted_data, new_entry],
                    ignore_index=True
                )
                
                # Display results
                risk_class = f"risk-{risk_level.lower()}"
                st.markdown(
                    f'<div class="{risk_class}">'
                    f'<h3>Risk Assessment: {risk_level}</h3>'
                    f'<p>Probability: {risk_proba:.1%}</p>'
                    f'</div>',
                    unsafe_allow_html=True
                )
                
                # Show interventions
                st.subheader("Recommended Interventions")
                for intervention in get_interventions(risk_level):
                    st.markdown(f'<div class="intervention-card">‚úÖ {intervention}</div>', 
                              unsafe_allow_html=True)

def bulk_upload():
    st.header("Bulk Data Upload")
    
    uploaded_file = st.file_uploader("Upload Excel or CSV file", type=["xlsx", "csv"])
    
    if uploaded_file is not None:
        try:
            if uploaded_file.name.endswith('.xlsx'):
                new_data = pd.read_excel(uploaded_file)
            else:
                new_data = pd.read_csv(uploaded_file)
            
            # Validate required columns - only those the model expects
            required_cols = [
                'n_ShInfection', 'mean_ShEgg', 'n_female', 'Pop', 'LakeYN',
                'distance', 'FloatingVeg', 'Depth', 'width_shore', 'Bulinus',
                'Biomph', 'circ_score'
            ]
            
            missing_cols = [col for col in required_cols if col not in new_data.columns]
            if missing_cols:
                st.error(f"Missing required columns: {', '.join(missing_cols)}")
                return
            
            # Process data
            model = _load_model()
            if model:
                # Only use the features the model was trained with
                X = new_data[required_cols]
                
                probas = model.predict_proba(X)[:, 1]
                new_data['Risk_Probability'] = probas
                new_data['Risk_Level'] = pd.cut(probas, 
                                              bins=[0, 0.3, 0.7, 1],
                                              labels=['Low', 'Medium', 'High'])
                
                # Add missing metadata if needed
                for col in ['Village', 'Site', 'Date']:
                    if col not in new_data.columns:
                        new_data[col] = "Unknown"
                
                st.session_state.submitted_data = pd.concat(
                    [st.session_state.submitted_data, new_data],
                    ignore_index=True
                )
                
                st.success(f"Successfully processed {len(new_data)} records!")
                
                # Show summary
                st.subheader("Risk Distribution")
                risk_counts = new_data['Risk_Level'].value_counts()
                st.bar_chart(risk_counts)
                
                # Show high-risk alerts
                high_risk = new_data[new_data['Risk_Level'] == 'High']
                if not high_risk.empty:
                    st.warning(f"‚ö†Ô∏è {len(high_risk)} high-risk locations detected!")
        except Exception as e:
            st.error(f"Error processing file: {str(e)}")

def data_management():
    st.header("Data Management")
    
    if not st.session_state.submitted_data.empty:
        st.subheader("Collected Data")
        st.dataframe(st.session_state.submitted_data)
        
        # Export options
        st.subheader("Export Data")
        
        col1, col2 = st.columns(2)
        
        with col1:
            # CSV export
            csv = st.session_state.submitted_data.to_csv(index=False).encode('utf-8')
            st.download_button(
                label="Download as CSV",
                data=csv,
                file_name="schisto_risk_data.csv",
                mime="text/csv"
            )
        
        with col2:
            # Excel export using BytesIO
            output = BytesIO()
            with pd.ExcelWriter(output, engine='openpyxl') as writer:
                st.session_state.submitted_data.to_excel(writer, index=False)
            excel_data = output.getvalue()
            st.download_button(
                label="Download as Excel",
                data=excel_data,
                file_name="schisto_risk_data.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
            )
    else:
        st.info("No data collected yet")

def main():
    st.title("üåç OH-FGS Schistosomiasis Risk Prediction")
    
    tab1, tab2, tab3 = st.tabs(["Individual Assessment", "Bulk Upload", "Data Management"])
    
    with tab1:
        show_input_form()
    
    with tab2:
        bulk_upload()
    
    with tab3:
        data_management()

if __name__ == "__main__":
    main()
